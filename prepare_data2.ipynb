{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.import_data as import_data\n",
    "import modules.natural_language_treatment as nlt\n",
    "from swifter import set_defaults\n",
    "set_defaults(\n",
    "    npartitions=24,\n",
    "    dask_threshold=10,\n",
    "    scheduler=\"processes\",\n",
    "    progress_bar=True,\n",
    "    progress_bar_desc=True,\n",
    "    allow_dask_on_strings=True,\n",
    "    force_parallel=True,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère l'ensemble des séries contenus dans notre base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serie</th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot_(1)</td>\n",
       "      <td>data/transcripts/1___Lost/01/01__Pilot_(1).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>Pilot_(2)</td>\n",
       "      <td>data/transcripts/1___Lost/01/02__Pilot_(2).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabula_rasa</td>\n",
       "      <td>data/transcripts/1___Lost/01/03__Tabula_rasa.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>Walkabout</td>\n",
       "      <td>data/transcripts/1___Lost/01/04__Walkabout.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>White_rabbit</td>\n",
       "      <td>data/transcripts/1___Lost/01/05__White_rabbit.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Lost</td>\n",
       "      <td>06</td>\n",
       "      <td>15</td>\n",
       "      <td>Across_The_Sea</td>\n",
       "      <td>data/transcripts/1___Lost/06/15__Across_The_Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Lost</td>\n",
       "      <td>06</td>\n",
       "      <td>16</td>\n",
       "      <td>What_They_Died_For</td>\n",
       "      <td>data/transcripts/1___Lost/06/16__What_They_Die...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Lost</td>\n",
       "      <td>06</td>\n",
       "      <td>17</td>\n",
       "      <td>The_End</td>\n",
       "      <td>data/transcripts/1___Lost/06/17__The_End.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Lost</td>\n",
       "      <td>06</td>\n",
       "      <td>98</td>\n",
       "      <td>New_Man_In_Charge</td>\n",
       "      <td>data/transcripts/1___Lost/06/98__New_Man_In_Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Lost</td>\n",
       "      <td>06</td>\n",
       "      <td>99</td>\n",
       "      <td>Jimmy_Kimmel_Live</td>\n",
       "      <td>data/transcripts/1___Lost/06/99__Jimmy_Kimmel_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    serie season  episode_number        episode_name  \\\n",
       "0    Lost     01               1           Pilot_(1)   \n",
       "1    Lost     01               2           Pilot_(2)   \n",
       "2    Lost     01               3         Tabula_rasa   \n",
       "3    Lost     01               4           Walkabout   \n",
       "4    Lost     01               5        White_rabbit   \n",
       "..    ...    ...             ...                 ...   \n",
       "120  Lost     06              15      Across_The_Sea   \n",
       "121  Lost     06              16  What_They_Died_For   \n",
       "122  Lost     06              17             The_End   \n",
       "123  Lost     06              98   New_Man_In_Charge   \n",
       "124  Lost     06              99   Jimmy_Kimmel_Live   \n",
       "\n",
       "                                                  path  \n",
       "0       data/transcripts/1___Lost/01/01__Pilot_(1).txt  \n",
       "1       data/transcripts/1___Lost/01/02__Pilot_(2).txt  \n",
       "2     data/transcripts/1___Lost/01/03__Tabula_rasa.txt  \n",
       "3       data/transcripts/1___Lost/01/04__Walkabout.txt  \n",
       "4    data/transcripts/1___Lost/01/05__White_rabbit.txt  \n",
       "..                                                 ...  \n",
       "120  data/transcripts/1___Lost/06/15__Across_The_Se...  \n",
       "121  data/transcripts/1___Lost/06/16__What_They_Die...  \n",
       "122       data/transcripts/1___Lost/06/17__The_End.txt  \n",
       "123  data/transcripts/1___Lost/06/98__New_Man_In_Ch...  \n",
       "124  data/transcripts/1___Lost/06/99__Jimmy_Kimmel_...  \n",
       "\n",
       "[125 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paths_episodes = import_data.get_df_paths_episodes()\n",
    "df_paths_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f91555e6df2c4dc8a5473f2489dee130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/swifter/swifter.py:309\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[0;32m--> 309\u001b[0m     tmp_df \u001b[39m=\u001b[39m func(sample, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    310\u001b[0m     sample_df \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:32\u001b[0m, in \u001b[0;36mlematize_transcript_and_save\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlematize_transcript_and_save\u001b[39m(path):\n\u001b[0;32m---> 32\u001b[0m   lematized \u001b[39m=\u001b[39m get_lemmatized_transcript_from_path(path)\n\u001b[1;32m     33\u001b[0m   save_array_to_path(lematized, \u001b[39m'\u001b[39m\u001b[39mdata/lemmatized/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mdata/transcripts/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:22\u001b[0m, in \u001b[0;36mget_lemmatized_transcript_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_lemmatized_transcript_from_path\u001b[39m(path):\n\u001b[0;32m---> 22\u001b[0m   transcript \u001b[39m=\u001b[39m load_transcript_from_path(path)\n\u001b[1;32m     23\u001b[0m   \u001b[39mreturn\u001b[39;00m lemmatize_sentence(transcript)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:17\u001b[0m, in \u001b[0;36mload_transcript_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_transcript_from_path\u001b[39m(path):\n\u001b[0;32m---> 17\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     18\u001b[0m     transcript \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/baptiste/Documents/github/courses/movies-recommendation-and-subtitles-analysis/prepare_data2.ipynb Cellule 5\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/baptiste/Documents/github/courses/movies-recommendation-and-subtitles-analysis/prepare_data2.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nlt\u001b[39m.\u001b[39;49mlematize_df_path_episodes_and_save(df_paths_episodes)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:37\u001b[0m, in \u001b[0;36mlematize_df_path_episodes_and_save\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlematize_df_path_episodes_and_save\u001b[39m(df):\n\u001b[0;32m---> 37\u001b[0m   df[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mswifter\u001b[39m.\u001b[39;49mapply(lematize_transcript_and_save)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/swifter/swifter.py:329\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar:\n\u001b[1;32m    328\u001b[0m     tqdm\u001b[39m.\u001b[39mpandas(desc\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_progress_bar_desc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mPandas Apply\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 329\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj\u001b[39m.\u001b[39;49mprogress_apply(func, convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype, args\u001b[39m=\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    330\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    331\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_obj\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tqdm/std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[0;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[39m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[1;32m    803\u001b[0m \u001b[39m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39;49m(df, df_function)(wrapper, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    806\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    807\u001b[0m     t\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/tqdm/std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    795\u001b[0m     \u001b[39m# update tbar correctly\u001b[39;00m\n\u001b[1;32m    796\u001b[0m     \u001b[39m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[1;32m    797\u001b[0m     \u001b[39m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[1;32m    798\u001b[0m     \u001b[39m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[1;32m    799\u001b[0m     t\u001b[39m.\u001b[39mupdate(n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m t\u001b[39m.\u001b[39mtotal \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m t\u001b[39m.\u001b[39mtotal \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 800\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:32\u001b[0m, in \u001b[0;36mlematize_transcript_and_save\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlematize_transcript_and_save\u001b[39m(path):\n\u001b[0;32m---> 32\u001b[0m   lematized \u001b[39m=\u001b[39m get_lemmatized_transcript_from_path(path)\n\u001b[1;32m     33\u001b[0m   save_array_to_path(lematized, \u001b[39m'\u001b[39m\u001b[39mdata/lemmatized/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mdata/transcripts/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     34\u001b[0m   \u001b[39mdel\u001b[39;00m lematized\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:23\u001b[0m, in \u001b[0;36mget_lemmatized_transcript_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_lemmatized_transcript_from_path\u001b[39m(path):\n\u001b[1;32m     22\u001b[0m   transcript \u001b[39m=\u001b[39m load_transcript_from_path(path)\n\u001b[0;32m---> 23\u001b[0m   \u001b[39mreturn\u001b[39;00m lemmatize_sentence(transcript)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:13\u001b[0m, in \u001b[0;36mlemmatize_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize_sentence\u001b[39m(sentence):\n\u001b[0;32m---> 13\u001b[0m   nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     14\u001b[0m   \u001b[39mreturn\u001b[39;00m [word\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m nlp(sentence)]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m     \u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     55\u001b[0m         name,\n\u001b[1;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/util.py:442\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m get_lang_class(name\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mblank:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))()\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m is_package(name):  \u001b[39m# installed as package\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_package(name, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m Path(name)\u001b[39m.\u001b[39mexists():  \u001b[39m# path to model data directory\u001b[39;00m\n\u001b[1;32m    444\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(Path(name), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/util.py:478\u001b[0m, in \u001b[0;36mload_model_from_package\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[39m\"\"\"Load a model from an installed package.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \n\u001b[1;32m    463\u001b[0m \u001b[39mname (str): The package name.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[39mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39mimport_module(name)\n\u001b[0;32m--> 478\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mload(vocab\u001b[39m=\u001b[39;49mvocab, disable\u001b[39m=\u001b[39;49mdisable, enable\u001b[39m=\u001b[39;49menable, exclude\u001b[39m=\u001b[39;49mexclude, config\u001b[39m=\u001b[39;49mconfig)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/en_core_web_sm/__init__.py:10\u001b[0m, in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moverrides):\n\u001b[0;32m---> 10\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_init_py(\u001b[39m__file__\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moverrides)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/util.py:659\u001b[0m, in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m model_path\u001b[39m.\u001b[39mexists():\n\u001b[1;32m    658\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE052\u001b[39m.\u001b[39mformat(path\u001b[39m=\u001b[39mdata_path))\n\u001b[0;32m--> 659\u001b[0m \u001b[39mreturn\u001b[39;00m load_model_from_path(\n\u001b[1;32m    660\u001b[0m     data_path,\n\u001b[1;32m    661\u001b[0m     vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m    662\u001b[0m     meta\u001b[39m=\u001b[39;49mmeta,\n\u001b[1;32m    663\u001b[0m     disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m    664\u001b[0m     enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m    665\u001b[0m     exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m    666\u001b[0m     config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m    667\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/util.py:524\u001b[0m, in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    515\u001b[0m config \u001b[39m=\u001b[39m load_config(config_path, overrides\u001b[39m=\u001b[39moverrides)\n\u001b[1;32m    516\u001b[0m nlp \u001b[39m=\u001b[39m load_model_from_config(\n\u001b[1;32m    517\u001b[0m     config,\n\u001b[1;32m    518\u001b[0m     vocab\u001b[39m=\u001b[39mvocab,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m     meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m    523\u001b[0m )\n\u001b[0;32m--> 524\u001b[0m \u001b[39mreturn\u001b[39;00m nlp\u001b[39m.\u001b[39;49mfrom_disk(model_path, exclude\u001b[39m=\u001b[39;49mexclude, overrides\u001b[39m=\u001b[39;49moverrides)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/language.py:2125\u001b[0m, in \u001b[0;36mLanguage.from_disk\u001b[0;34m(self, path, exclude, overrides)\u001b[0m\n\u001b[1;32m   2122\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mexists() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:  \u001b[39m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m   2123\u001b[0m     \u001b[39m# Convert to list here in case exclude is (default) tuple\u001b[39;00m\n\u001b[1;32m   2124\u001b[0m     exclude \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(exclude) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mvocab\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m-> 2125\u001b[0m util\u001b[39m.\u001b[39;49mfrom_disk(path, deserializers, exclude)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_path \u001b[39m=\u001b[39m path  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   2127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_link_components()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/util.py:1369\u001b[0m, in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1367\u001b[0m     \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n\u001b[1;32m   1368\u001b[0m     \u001b[39mif\u001b[39;00m key\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude:\n\u001b[0;32m-> 1369\u001b[0m         reader(path \u001b[39m/\u001b[39;49m key)\n\u001b[1;32m   1370\u001b[0m \u001b[39mreturn\u001b[39;00m path\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/language.py:2101\u001b[0m, in \u001b[0;36mLanguage.from_disk.<locals>.deserialize_vocab\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeserialize_vocab\u001b[39m(path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     \u001b[39mif\u001b[39;00m path\u001b[39m.\u001b[39mexists():\n\u001b[0;32m-> 2101\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvocab\u001b[39m.\u001b[39;49mfrom_disk(path, exclude\u001b[39m=\u001b[39;49mexclude)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/vocab.pyx:492\u001b[0m, in \u001b[0;36mspacy.vocab.Vocab.from_disk\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/vectors.pyx:629\u001b[0m, in \u001b[0;36mspacy.vectors.Vectors.from_disk\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/util.py:1360\u001b[0m, in \u001b[0;36mfrom_disk\u001b[0;34m(path, readers, exclude)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             writer(path \u001b[39m/\u001b[39m key)\n\u001b[1;32m   1357\u001b[0m     \u001b[39mreturn\u001b[39;00m path\n\u001b[0;32m-> 1360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_disk\u001b[39m(\n\u001b[1;32m   1361\u001b[0m     path: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m   1362\u001b[0m     readers: Dict[\u001b[39mstr\u001b[39m, Callable[[Path], \u001b[39mNone\u001b[39;00m]],\n\u001b[1;32m   1363\u001b[0m     exclude: Iterable[\u001b[39mstr\u001b[39m],\n\u001b[1;32m   1364\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Path:\n\u001b[1;32m   1365\u001b[0m     path \u001b[39m=\u001b[39m ensure_path(path)\n\u001b[1;32m   1366\u001b[0m     \u001b[39mfor\u001b[39;00m key, reader \u001b[39min\u001b[39;00m readers\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1367\u001b[0m         \u001b[39m# Split to support file names like meta.json\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlt.lematize_df_path_episodes_and_save(df_paths_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.import_data as import_data\n",
    "import modules.natural_language_treatment as nlt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère l'ensemble des séries contenus dans notre base de donnée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serie</th>\n",
       "      <th>season</th>\n",
       "      <th>episode_number</th>\n",
       "      <th>episode_name</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilot_(1)</td>\n",
       "      <td>data/transcripts/1___Lost/01/01__Pilot_(1).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>2</td>\n",
       "      <td>Pilot_(2)</td>\n",
       "      <td>data/transcripts/1___Lost/01/02__Pilot_(2).txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>3</td>\n",
       "      <td>Tabula_rasa</td>\n",
       "      <td>data/transcripts/1___Lost/01/03__Tabula_rasa.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>4</td>\n",
       "      <td>Walkabout</td>\n",
       "      <td>data/transcripts/1___Lost/01/04__Walkabout.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lost</td>\n",
       "      <td>01</td>\n",
       "      <td>5</td>\n",
       "      <td>White_rabbit</td>\n",
       "      <td>data/transcripts/1___Lost/01/05__White_rabbit.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81817</th>\n",
       "      <td>Mind_of_a_Chef</td>\n",
       "      <td>04</td>\n",
       "      <td>3</td>\n",
       "      <td>Rome</td>\n",
       "      <td>data/transcripts/5480___Mind_of_a_Chef/04/03__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81818</th>\n",
       "      <td>Mind_of_a_Chef</td>\n",
       "      <td>04</td>\n",
       "      <td>4</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>data/transcripts/5480___Mind_of_a_Chef/04/04__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81819</th>\n",
       "      <td>Mind_of_a_Chef</td>\n",
       "      <td>04</td>\n",
       "      <td>5</td>\n",
       "      <td>Past</td>\n",
       "      <td>data/transcripts/5480___Mind_of_a_Chef/04/05__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81820</th>\n",
       "      <td>Mind_of_a_Chef</td>\n",
       "      <td>04</td>\n",
       "      <td>6</td>\n",
       "      <td>Hustle</td>\n",
       "      <td>data/transcripts/5480___Mind_of_a_Chef/04/06__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81821</th>\n",
       "      <td>Mind_of_a_Chef</td>\n",
       "      <td>04</td>\n",
       "      <td>7</td>\n",
       "      <td>Napkin</td>\n",
       "      <td>data/transcripts/5480___Mind_of_a_Chef/04/07__...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81822 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                serie season  episode_number  episode_name  \\\n",
       "0                Lost     01               1     Pilot_(1)   \n",
       "1                Lost     01               2     Pilot_(2)   \n",
       "2                Lost     01               3   Tabula_rasa   \n",
       "3                Lost     01               4     Walkabout   \n",
       "4                Lost     01               5  White_rabbit   \n",
       "...               ...    ...             ...           ...   \n",
       "81817  Mind_of_a_Chef     04               3          Rome   \n",
       "81818  Mind_of_a_Chef     04               4        Hunger   \n",
       "81819  Mind_of_a_Chef     04               5          Past   \n",
       "81820  Mind_of_a_Chef     04               6        Hustle   \n",
       "81821  Mind_of_a_Chef     04               7        Napkin   \n",
       "\n",
       "                                                    path  \n",
       "0         data/transcripts/1___Lost/01/01__Pilot_(1).txt  \n",
       "1         data/transcripts/1___Lost/01/02__Pilot_(2).txt  \n",
       "2       data/transcripts/1___Lost/01/03__Tabula_rasa.txt  \n",
       "3         data/transcripts/1___Lost/01/04__Walkabout.txt  \n",
       "4      data/transcripts/1___Lost/01/05__White_rabbit.txt  \n",
       "...                                                  ...  \n",
       "81817  data/transcripts/5480___Mind_of_a_Chef/04/03__...  \n",
       "81818  data/transcripts/5480___Mind_of_a_Chef/04/04__...  \n",
       "81819  data/transcripts/5480___Mind_of_a_Chef/04/05__...  \n",
       "81820  data/transcripts/5480___Mind_of_a_Chef/04/06__...  \n",
       "81821  data/transcripts/5480___Mind_of_a_Chef/04/07__...  \n",
       "\n",
       "[81822 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paths_episodes = import_data.get_df_paths_episodes()\n",
    "df_paths_episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/swifter/swifter.py:309\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[0;32m--> 309\u001b[0m     tmp_df \u001b[39m=\u001b[39m func(sample, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    310\u001b[0m     sample_df \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39mapply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:32\u001b[0m, in \u001b[0;36mlematize_transcript_and_save\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlematize_transcript_and_save\u001b[39m(path):\n\u001b[0;32m---> 32\u001b[0m   lematized \u001b[39m=\u001b[39m get_lemmatized_transcript_from_path(path)\n\u001b[1;32m     33\u001b[0m   save_array_to_path(lematized, \u001b[39m'\u001b[39m\u001b[39mdata/lemmatized/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m path)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:22\u001b[0m, in \u001b[0;36mget_lemmatized_transcript_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_lemmatized_transcript_from_path\u001b[39m(path):\n\u001b[0;32m---> 22\u001b[0m   transcript \u001b[39m=\u001b[39m load_transcript_from_path(path)\n\u001b[1;32m     23\u001b[0m   \u001b[39mreturn\u001b[39;00m lemmatize_sentence(transcript)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:17\u001b[0m, in \u001b[0;36mload_transcript_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_transcript_from_path\u001b[39m(path):\n\u001b[0;32m---> 17\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m     18\u001b[0m     transcript \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not Series",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/baptiste/Documents/github/courses/movies-recommendation-and-subtitles-analysis/prepare_data2.ipynb Cellule 4\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/baptiste/Documents/github/courses/movies-recommendation-and-subtitles-analysis/prepare_data2.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nlt\u001b[39m.\u001b[39;49mlematize_df_path_episodes_and_save(df_paths_episodes)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:37\u001b[0m, in \u001b[0;36mlematize_df_path_episodes_and_save\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlematize_df_path_episodes_and_save\u001b[39m(df):\n\u001b[0;32m---> 37\u001b[0m   df[\u001b[39m'\u001b[39;49m\u001b[39mpath\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mswifter\u001b[39m.\u001b[39;49mapply(lematize_transcript_and_save)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/swifter/swifter.py:318\u001b[0m, in \u001b[0;36mSeriesAccessor.apply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39mexcept\u001b[39;00m ERRORS_TO_HANDLE:  \u001b[39m# if can't vectorize, estimate time to pandas apply\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrapped_apply(func, convert_dtype\u001b[39m=\u001b[39mconvert_dtype, args\u001b[39m=\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m--> 318\u001b[0m     timed \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39;49mtimeit(wrapped, number\u001b[39m=\u001b[39;49mN_REPEATS)\n\u001b[1;32m    319\u001b[0m     sample_proc_est \u001b[39m=\u001b[39m timed \u001b[39m/\u001b[39m N_REPEATS\n\u001b[1;32m    320\u001b[0m     est_apply_duration \u001b[39m=\u001b[39m sample_proc_est \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_SAMPLE_SIZE \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nrows\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/timeit.py:234\u001b[0m, in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtimeit\u001b[39m(stmt\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpass\u001b[39m\u001b[39m\"\u001b[39m, setup\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpass\u001b[39m\u001b[39m\"\u001b[39m, timer\u001b[39m=\u001b[39mdefault_timer,\n\u001b[1;32m    232\u001b[0m            number\u001b[39m=\u001b[39mdefault_number, \u001b[39mglobals\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m     \u001b[39m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mreturn\u001b[39;00m Timer(stmt, setup, timer, \u001b[39mglobals\u001b[39;49m)\u001b[39m.\u001b[39;49mtimeit(number)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.8/Frameworks/Python.framework/Versions/3.10/lib/python3.10/timeit.py:178\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    176\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    179\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer, _stmt)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/swifter/swifter.py:227\u001b[0m, in \u001b[0;36mSeriesAccessor._wrapped_apply.<locals>.wrapped\u001b[0;34m()\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m():\n\u001b[1;32m    226\u001b[0m     \u001b[39mwith\u001b[39;00m suppress_stdout_stderr_logging():\n\u001b[0;32m--> 227\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_obj\u001b[39m.\u001b[39;49miloc[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_SAMPLE_INDEX]\u001b[39m.\u001b[39;49mapply(func, convert_dtype\u001b[39m=\u001b[39;49mconvert_dtype, args\u001b[39m=\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/apply.py:1105\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1104\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/apply.py:1156\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1155\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1156\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1157\u001b[0m             values,\n\u001b[1;32m   1158\u001b[0m             f,\n\u001b[1;32m   1159\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1163\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2918\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:32\u001b[0m, in \u001b[0;36mlematize_transcript_and_save\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlematize_transcript_and_save\u001b[39m(path):\n\u001b[0;32m---> 32\u001b[0m   lematized \u001b[39m=\u001b[39m get_lemmatized_transcript_from_path(path)\n\u001b[1;32m     33\u001b[0m   save_array_to_path(lematized, \u001b[39m'\u001b[39m\u001b[39mdata/lemmatized/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m path)\n\u001b[1;32m     34\u001b[0m   \u001b[39mdel\u001b[39;00m lematized\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:23\u001b[0m, in \u001b[0;36mget_lemmatized_transcript_from_path\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_lemmatized_transcript_from_path\u001b[39m(path):\n\u001b[1;32m     22\u001b[0m   transcript \u001b[39m=\u001b[39m load_transcript_from_path(path)\n\u001b[0;32m---> 23\u001b[0m   \u001b[39mreturn\u001b[39;00m lemmatize_sentence(transcript)\n",
      "File \u001b[0;32m~/Documents/github/courses/movies-recommendation-and-subtitles-analysis/modules/natural_language_treatment.py:14\u001b[0m, in \u001b[0;36mlemmatize_sentence\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize_sentence\u001b[39m(sentence):\n\u001b[1;32m     13\u001b[0m   nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m   \u001b[39mreturn\u001b[39;00m [word\u001b[39m.\u001b[39mlemma_ \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m nlp(sentence)]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/language.py:1011\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     error_handler \u001b[39m=\u001b[39m proc\u001b[39m.\u001b[39mget_error_handler()\n\u001b[1;32m   1010\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     doc \u001b[39m=\u001b[39m proc(doc, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcomponent_cfg\u001b[39m.\u001b[39;49mget(name, {}))  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m     \u001b[39m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE109\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:135\u001b[0m, in \u001b[0;36mLemmatizer.__call__\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc:\n\u001b[1;32m    134\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverwrite \u001b[39mor\u001b[39;00m token\u001b[39m.\u001b[39mlemma \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m             token\u001b[39m.\u001b[39mlemma_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlemmatize(token)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m doc\n\u001b[1;32m    137\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:243\u001b[0m, in \u001b[0;36mLemmatizer.rule_lemmatize\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m form:\n\u001b[1;32m    242\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m \u001b[39melif\u001b[39;00m form \u001b[39min\u001b[39;00m index \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m form\u001b[39m.\u001b[39;49misalpha():\n\u001b[1;32m    244\u001b[0m     forms\u001b[39m.\u001b[39mappend(form)\n\u001b[1;32m    245\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nlt.lematize_df_path_episodes_and_save(df_paths_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
